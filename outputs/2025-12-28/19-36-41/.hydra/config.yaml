model_pool:
  instances:
  - name: cross-encoder/ms-marco-MiniLM-L-6-v2
    backend: mps
    device: mps
    quantization: fp16
    compile_model: false
    max_length: 200
  - name: cross-encoder/ms-marco-MiniLM-L-6-v2
    backend: mps
    device: mps
    quantization: fp16
    compile_model: false
    max_length: 200
  - name: cross-encoder/ms-marco-MiniLM-L-6-v2
    backend: mps
    device: mps
    quantization: fp16
    compile_model: false
    max_length: 200
  routing_strategy: round_robin
tokenizer_pool:
  enabled: true
  num_workers: 3
  model_name: ''
batching:
  enabled: false
  max_batch_size: 32
  timeout_ms: 100.0
  length_aware: false
server:
  host: 0.0.0.0
  grpc_port: 50051
  http_port: 8080
  grpc_workers: 10
name: Multi-Model Pool (3x MPS)
description: Three MPS model instances with round-robin routing for parallel inference
experiment:
  batch_sizes:
  - 16
  - 32
  concurrency_levels:
  - 2
  - 4
  warmup_iterations: 10
