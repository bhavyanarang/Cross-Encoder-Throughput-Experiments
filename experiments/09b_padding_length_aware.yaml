# Experiment 09b: Length-Aware Batching
# Run with length-aware batching to reduce padding waste
name: "09b_padding_length_aware"
description: "Length-aware batching - sorted by token length"

model:
  backend: "mps"
  mps:
    fp16: true

batching:
  enabled: false
  max_batch_size: 64
  timeout_ms: 50
  length_aware_batching: true  # ENABLED - sort pairs by length

experiment:
  batch_sizes: [32, 64, 96]
  concurrency_levels: [1]
  benchmark_requests: 150
