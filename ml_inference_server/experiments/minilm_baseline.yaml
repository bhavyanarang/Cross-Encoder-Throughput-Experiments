# Experiment: MiniLM Baseline (FP32, no quantization)
name: "minilm_baseline"
description: "Baseline experiment with MiniLM-L6-v2 on MPS (FP32)"

model:
  name: "sentence-transformers/all-MiniLM-L6-v2"
  device: "mps"
  quantized: false
  quantization_mode: "none"
  backend: "pytorch"

# Uses default experiment parameters from base_config.yaml

