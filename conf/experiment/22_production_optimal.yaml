# @package _global_

defaults:
  - override /model_pool: default
  - override /batching: default
  - override /tokenizer_pool: default
  - override /server: default

name: "22_production_optimal"
description: "Production config: batch=64, conc=2, dynamic batching (from Exp 08a)"

model_pool:
  instances:
    - name: "cross-encoder/ms-marco-MiniLM-L-6-v2"
      device: "mps"
      backend: "mps"
      quantization: fp16
      compile_model: false
      max_length: 175

batching:
  enabled: true
  max_batch_size: 256
  timeout_ms: 50.0
  length_aware: true

scheduler:
  enable_length_aware_batching: true
  enable_stage_timing: true

experiment:
  batch_sizes: [96]
  concurrency_levels: [1, 2, 3, 4, 6, 8, 12]
