# @package _global_
defaults:
  - override /model_pool: default
  - override /batching: default

name: cuda_test
description: "Basic test of CUDA backend"

model_pool:
  instances:
    - name: "cross-encoder/ms-marco-MiniLM-L-6-v2"
      device: "cuda"
      backend: "pytorch"
      quantization: "fp16"
      compile: false

server:
  host: "0.0.0.0"
  grpc_port: 50051
  http_port: 8080
  grpc_workers: 10

batching:
  enabled: true
  max_batch_size: 32
  timeout_ms: 100
