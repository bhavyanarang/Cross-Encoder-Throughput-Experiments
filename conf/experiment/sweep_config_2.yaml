# @package _global_

batching:
  enabled: true
  length_aware: false
  max_batch_size: 96
  timeout_ms: 10
defaults:
- override /model_pool: default
- override /batching: default
- override /tokenizer_pool: default
- override /server: default
description: Dynamic batching timeout sweep across backends and timeout values
experiment:
  batch_sizes:
  - 32
  concurrency_levels:
  - 4
model_pool:
  instances:
  - backend: mps
    compile_model: false
    device: mps
    max_length: 512
    name: cross-encoder/ms-marco-MiniLM-L-6-v2
    quantization: fp16
name: 08_dynamic_batch_timeout_sweep_mps_10ms
