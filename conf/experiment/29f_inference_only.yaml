# @package _global_

defaults:
  - override /model_pool: default
  - override /batching: default
  - override /tokenizer_pool: default
  - override /server: default
  - override /pipeline: default

name: "29f_inference_only"
description: "Inference-only baseline (128 batch size, 16 concurrency)"

pipeline:
  enabled: true
  mode: "inference_only"

batching:
  enabled: false

experiment:
  batch_sizes: [128]
  concurrency_levels: [16]
  benchmark_duration_s: 60
  prefill_requests: 128
  dataset_size: 20000
