# @package _global_

defaults:
  - override /model_pool: default
  - override /batching: default
  - override /tokenizer_pool: default
  - override /server: default

# Experiment 11: Quantization Comparison - Sweep quantization modes
name: "11_quantization_sweep"
description: "Compare FP32, FP16, and INT8 quantization on MPS backend"
# Note: quantization_mode list will be expanded, and each config will need
# different settings (quantized: true for int8, fp16: true/false for fp16/fp32)
# The sweep handler should handle this, but if not, we may need custom logic

# Quantization sweep: will be expanded into multiple configs
model_pool:
  instances:
    - name: "cross-encoder/ms-marco-MiniLM-L-6-v2"
      backend: "mps"
      device: "mps"
      quantization: ["fp32", "fp16", "int8"]
      compile_model: false
      max_length: 512

batching:
  enabled: false
  max_batch_size: 8
  timeout_ms: 100.0
  length_aware: false

experiment:
  batch_sizes: [96]
  concurrency_levels: [1]
